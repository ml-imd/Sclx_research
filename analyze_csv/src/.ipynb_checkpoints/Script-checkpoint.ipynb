{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import *\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from ntpath import split, basename\n",
    "from os import stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(path, label_col = None, return_dataframe = False):\n",
    "    dataframe = pd.read_csv(path)\n",
    "    if(label_col is None):\n",
    "        X = dataframe.to_numpy()\n",
    "    else:\n",
    "        X = np.array(dataframe.drop(label_col, axis = 1))\n",
    "    \n",
    "    if(return_dataframe):\n",
    "        return X, dataframe\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(method, parameters = {}):\n",
    "    methods = {\"KMeans\" : KMeans,\n",
    "               \"AffinityPropagation\" : AffinityPropagation,\n",
    "               \"AgglomerativeClustering\" : AgglomerativeClustering,\n",
    "               \"Birch\" : Birch,\n",
    "               \"DBSCAN\" : DBSCAN,\n",
    "               \"FeatureAgglomeration\" : FeatureAgglomeration,\n",
    "               \"MiniBatchKMeans\" : MiniBatchKMeans,\n",
    "               \"MeanShift\" : MeanShift,\n",
    "               \"OPTICS\" : OPTICS,\n",
    "               \"SpectralClustering\" : SpectralClustering,\n",
    "               \"SpectralBiclustering\" : SpectralBiclustering,\n",
    "               \"SpectralCoclustering\" : SpectralCoclustering,\n",
    "               \"GaussianMixture\": GaussianMixture,}\n",
    "               \n",
    "    return methods[method](**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(X, clusters):\n",
    "    slt_score = silhouette_score(X, clusters)\n",
    "    db_score = davies_bouldin_score(X, clusters)\n",
    "    return (slt_score, db_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileNameFromPath(path):\n",
    "    head, tail = split(path)\n",
    "    return tail or basename(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeData(file_name, method, slt_score, db_score, k = '-', seed = '-'): \n",
    "    file = open(file_name, 'a')\n",
    "    if(stat(file_name).st_size == 0):\n",
    "        file.write(\"method,n_cluster,seed,silhoutte,db\\n\")\n",
    "        print(\"method,n_cluster,seed,silhoutte,db\\n\")\n",
    "    \n",
    "    file.write(method + ',' + k + ',' + seed + ',' + slt_score + ',' + db_score + '\\n')\n",
    "    print(method + ',' + k + ',' + seed + ',' + slt_score + ',' + db_score + '\\n')\n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(path, method, file_name, parameters = {}, k_range = None, seed_values = None, label_col = None, export_dataset = False):\n",
    "    dataset = readData(path, label_col)\n",
    "    try:\n",
    "        if(k_range is not None and seed_values is not None):\n",
    "            for x in range(k_range[0], k_range[1]):\n",
    "                if(method == \"SpectralBiclustering\"):\n",
    "                    parameters[\"n_clusters\"] = (x, dataset.shape[1])\n",
    "                elif(method == \"GaussianMixture\"):\n",
    "                    parameters[\"n_components\"] = x;\n",
    "                else:\n",
    "                    parameters[\"n_clusters\"] = x\n",
    "                for y in seed_values:\n",
    "                    parameters[\"random_state\"] = y\n",
    "                    cluster_method = cluster(method, parameters)\n",
    "                    cluster_method.fit(dataset)\n",
    "                    if(method == \"SpectralBiclustering\" or method == \"SpectralCoclustering\"):\n",
    "                        scores = getScores(dataset, cluster_method.row_labels_)\n",
    "                    elif(method == \"GaussianMixture\"):\n",
    "                        scores = getScores(dataset, cluster_method.predict(dataset))\n",
    "                    else:\n",
    "                        scores = getScores(dataset, cluster_method.labels_)\n",
    "                    writeData(file_name, method, k = str(x), seed = str(y), slt_score = str(scores[0]), db_score = str(scores[1]))\n",
    "        elif(k_range is not None and seed_values is None):\n",
    "            for x in range(k_range[0], k_range[1]):\n",
    "                parameters[\"n_clusters\"] = x\n",
    "                cluster_method = cluster(method, parameters)\n",
    "                cluster_method.fit(dataset)\n",
    "                scores = getScores(dataset, cluster_method.labels_)\n",
    "                writeData(file_name, method, k = str(x), slt_score = str(scores[0]), db_score = str(scores[1]))\n",
    "        elif(k_range is None and seed_values is not None):\n",
    "            for y in seed_values:\n",
    "                parameters[\"random_state\"] = y\n",
    "                cluster_method = cluster(method, parameters)\n",
    "                cluster_method.fit(dataset)\n",
    "                scores = getScores(dataset, cluster_method.labels_)\n",
    "                writeData(file_name, method, seed = str(y), slt_score = str(scores[0]), db_score = str(scores[1]))\n",
    "        else:\n",
    "            cluster_method = cluster(method, parameters)\n",
    "            cluster_method.fit(dataset)\n",
    "            scores = getScores(dataset, cluster_method.labels_)\n",
    "            writeData(file_name, method, slt_score = str(scores[0]), db_score = str(scores[1]))\n",
    "    except MemoryError:\n",
    "        print(\"MemoryError in \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(path, method, k = None, seed = None, label_col = None, parameters = {}):\n",
    "    if(k is not None and seed is not None):\n",
    "        file_name = \"exported\" + '_' + fileNameFromPath(path) + '_' + method + '_' + str(k) + '_' + str(seed) + '.csv'\n",
    "    elif(k is not None and seed is None):\n",
    "        file_name = \"exported\" + '_' + fileNameFromPath(path) + '_' + method + '_' + str(k) + '.csv'\n",
    "    elif(k is None and seed is not None):\n",
    "        file_name = \"exported\" + '_' + fileNameFromPath(path) + '_' + method + '_' + str(seed) + '.csv'\n",
    "    else:\n",
    "        file_name = \"exported\" + '_' + fileNameFromPath(path) + '_' + method + '.csv'\n",
    "    dataset, dataframe = readData(path, label_col, True)\n",
    "    if(k is not None):\n",
    "        parameters[\"n_clusters\"] = k\n",
    "    if(seed is not None):\n",
    "        parameters[\"random_state\"] = seed\n",
    "    cluster_method = cluster(method, parameters)\n",
    "    cluster_method.fit(dataset)\n",
    "    scores = getScores(dataset, cluster_method.labels_)\n",
    "    print(\"Silhouette: \" + str(scores[0]))\n",
    "    print(\"Davies Bouldin: \" + str(scores[1]))\n",
    "    if(method == \"SpectralBiclustering\" or method == \"SpectralCoclustering\"):\n",
    "        dataframe[\"cluster\"] = cluster_method.row_labels_\n",
    "    else:\n",
    "        dataframe[\"cluster\"] = cluster_method.labels_\n",
    "        \n",
    "    dataframe.to_csv(file_name, index = False)\n",
    "    \n",
    "    parameters.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeAll(path, k_range, seed_values, label_col = None):\n",
    "    file_name = fileNameFromPath(path) + '_' + 'k' + str(k_range) +'_' + 'seed' + str(seed_values) + '.csv'\n",
    "    have_none = [\"DBSCAN\", \"OPTICS\", \"MeanShift\"]\n",
    "    have_k = [\"AgglomerativeClustering\", \"Birch\"]\n",
    "    have_seed_and_k = [\"KMeans\", \"MiniBatchKMeans\", \"GaussianMixture\"]\n",
    "    \n",
    "    for method in have_seed_and_k:\n",
    "        analyze(path, method, file_name, k_range = k_range, seed_values = seed_values, label_col = label_col, parameters = {})\n",
    "    for method in have_k:\n",
    "        analyze(path, method, file_name, k_range = k_range, label_col = label_col, parameters = {})\n",
    "    for method in have_none:\n",
    "        analyze(path, method, file_name, label_col = label_col, parameters = {})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
